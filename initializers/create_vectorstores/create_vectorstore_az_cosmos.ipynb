{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare LangChain Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def loadJSONsAtRuntime() -> dict:\n",
    "\tprint(\"Loading jsons into memory\")\n",
    "\n",
    "\tfilepath = '..\\extract_data\\extracted_data'\n",
    "\tjson_dicts = {}\n",
    "\n",
    "\tfor filename in os.listdir(filepath):\n",
    "\t\tf = os.path.join(filepath, filename)\n",
    "\t\tif os.path.isfile(f):\n",
    "\t\t\tprint(\"Loading json @ \" + f)\n",
    "\t\t\tjson_dict = json.loads(Path(f).read_text())\n",
    "\t\t\tchapterNumber = json_dict[\"Chapter Number\"]\n",
    "\t\t\tjson_dicts[chapterNumber] = json_dict\n",
    "\n",
    "\tprint(\"Loading jsons into memory completed.\")\n",
    "\treturn json_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting vectorstore creation...\n",
      "Loading json files into memory...\n",
      "Loading jsons into memory\n",
      "Loading json @ ..\\extract_data\\extracted_data\\1.json\n",
      "Loading json @ ..\\extract_data\\extracted_data\\28.json\n",
      "Loading jsons into memory completed.\n",
      "Filtering data...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../pdfplumber')\n",
    "\n",
    "import shutil\n",
    "\n",
    "print(\"Starting vectorstore creation...\")\n",
    "\n",
    "# load the json data into a dictionary\n",
    "# ......................................... #\n",
    "print(\"Loading json files into memory...\")\n",
    "json_dicts = loadJSONsAtRuntime()\n",
    "# ......................................... #\n",
    "\n",
    "\n",
    "\n",
    "# create langchain documents with the data we need\n",
    "# ......................................... #\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "docs = []\n",
    "print(\"Filtering data...\")\n",
    "\n",
    "for key,value in json_dicts.items():\n",
    "    json_dict = value\n",
    "\n",
    "    items = json_dict[\"Items\"]\n",
    "    chapterName = json_dict[\"Chapter Name\"]\n",
    "\n",
    "    for item in items:\n",
    "        prefix = item[\"Prefix\"]\n",
    "        hsHeadingName = item[\"HS Hdg Name\"]\n",
    "        hscode = item[\"HS Code\"]\n",
    "        description = item[\"Description\"]\n",
    "\n",
    "        content = \"Chapter Name: \" + chapterName + \" , HS Heading Name:\" + hsHeadingName + \" ,Prefix: \" + prefix +  \" , Description:\" + description\n",
    "        document = Document(\n",
    "            page_content=content,\n",
    "            metadata={ \"HS Code\": hscode }\n",
    "        )\n",
    "        docs.append(document)\n",
    "# ......................................... #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosmos Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexing_policy = {\n",
    "    \"indexingMode\": \"consistent\",\n",
    "    \"includedPaths\": [{\"path\": \"/*\"}],\n",
    "    \"excludedPaths\": [{\"path\": '/\"_etag\"/?'}],\n",
    "    \"vectorIndexes\": [{\"path\": \"/embedding\", \"type\": \"quantizedFlat\"}],\n",
    "}\n",
    "\n",
    "vector_embedding_policy = {\n",
    "    \"vectorEmbeddings\": [\n",
    "        {\n",
    "            \"path\": \"/embedding\",\n",
    "            \"dataType\": \"float32\",\n",
    "            \"distanceFunction\": \"cosine\",\n",
    "            \"dimensions\": 1536,\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below block took about 1 min 4s to complete with 2 tariff pdfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RehangaG\\AppData\\Local\\Temp\\ipykernel_19748\\560081400.py:23: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  embedding = OpenAIEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "from azure.cosmos import CosmosClient, PartitionKey\n",
    "from langchain_community.vectorstores.azure_cosmos_db_no_sql import (\n",
    "    AzureCosmosDBNoSqlVectorSearch,\n",
    ")\n",
    "# from langchain_openai import AzureOpenAIEmbeddings\n",
    "import openai\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "HOST = os.environ[\"COSMOS_ENDPOINT\"]\n",
    "KEY = os.environ[\"COSMOS_KEY\"]\n",
    "\n",
    "cosmos_client = CosmosClient(HOST, KEY)\n",
    "database_name = \"langchain_python_db\"\n",
    "container_name = \"langchain_python_container\"\n",
    "partition_key = PartitionKey(path=\"/id\")\n",
    "cosmos_container_properties = {\"partition_key\": partition_key}\n",
    "cosmos_database_properties = {\"id\": database_name}\n",
    "\n",
    "# openai_embeddings = AzureOpenAIEmbeddings(\n",
    "#     openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "# )\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "# insert the documents in AzureCosmosDBNoSql with their embedding\n",
    "vector_search = AzureCosmosDBNoSqlVectorSearch.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embedding,\n",
    "    cosmos_client=cosmos_client,\n",
    "    database_name=database_name,\n",
    "    container_name=container_name,\n",
    "    vector_embedding_policy=vector_embedding_policy,\n",
    "    indexing_policy=indexing_policy,\n",
    "    cosmos_container_properties=cosmos_container_properties,\n",
    "    cosmos_database_properties=cosmos_database_properties\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test using the vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter Name: Live animals  , HS Heading Name:Live bovine animals (+). ,Prefix: Buffalo: , Description:Pure-bred breeding animals\n"
     ]
    }
   ],
   "source": [
    "query = \"bison\"\n",
    "results = vector_search.similarity_search(query)\n",
    "\n",
    "print(results[0].page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
